{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ“Š Sentiment Model Comparison Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay
",
    "import matplotlib.pyplot as plt
",
    "import numpy as np
",
    "from tensorflow.keras.models import load_model
",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences
",
    "from tensorflow.keras.datasets import imdb
",
    "
",
    "models = {
",
    "    'RNN': '../models/rnn_model.h5',
",
    "    'LSTM': '../models/lstm_model.h5',
",
    "    'GRU': '../models/gru_model.h5',
",
    "    'BiLSTM (GloVe)': '../models/bidirectional_lstm_glove.h5',
",
    "    'BiGRU (GloVe)': '../models/bidirectional_gru_glove.h5'
",
    "}
",
    "
",
    "max_features = 10000
",
    "maxlen = 500
",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
",
    "x_test = pad_sequences(x_test, maxlen=maxlen)
",
    "
",
    "for name, path in models.items():
",
    "    print(f"\n{name} Results:")
",
    "    model = load_model(path)
",
    "    y_pred = (model.predict(x_test) > 0.5).astype("int32")
",
    "    print(classification_report(y_test, y_pred))
",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
",
    "    plt.title(f"Confusion Matrix: {name}")
",
    "    plt.show()"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
